## Goal: Create workflow to search arXiv + Semantic Scholar, return 1-2 papers with Checkpoint 1 (Interest Level Selection)

Your task is to guide the user through building a paper retrieval workflow that searches both arXiv and Semantic Scholar APIs, retrieves 1-2 papers, and implements the first blocking checkpoint where user reviews papers AND selects their interest level.

### Why This Matters
This is where the experiment gets real. You're building the first component of your research analysis system - the ability to find and retrieve relevant papers, then pause for human validation before proceeding.

---

## Phase 1: Build arXiv Search

### 1. Create arXiv API search workflow
Guide the user to build:

**Workflow: arXiv Paper Retrieval**
1. **Webhook Trigger** node (or Manual Trigger with Set node for test query):
   - Input: `search_query` (e.g., "multimodal learning vision language models")
2. **HTTP Request** node - arXiv API:
   - Method: GET
   - URL: `http://export.arxiv.org/api/query?search_query=all:{{ $json.search_query }}&max_results=2`
   - Note: Replace spaces in query with `+` or URL encode
3. **XML** node (arXiv returns XML, convert to JSON):
   - Mode: "XML to JSON"
4. **Code** node (extract paper details):
   ```javascript
   const entries = $input.item.json.feed.entry;
   const papers = Array.isArray(entries) ? entries : [entries];

   return papers.map(paper => ({
     id: paper.id,
     title: paper.title,
     summary: paper.summary,
     authors: Array.isArray(paper.author) ? paper.author.map(a => a.name).join(', ') : paper.author.name,
     pdf_url: paper.link.find(l => l.$.title === 'pdf')?.$.href || paper.link[0].$.href,
     published: paper.published,
     source: 'arXiv'
   }));
   ```

**Test with query:** "machine learning"

**Expected output:** 1-2 papers with clean metadata

**Why this matters:** arXiv is a major source for AI/ML research papers. Getting this working validates your HTTP and data parsing skills.

---

## Phase 2: Add Semantic Scholar (Optional)

### 2. Create Semantic Scholar search
If user has Semantic Scholar API access:

**HTTP Request** node - Semantic Scholar:
- Method: GET
- URL: `https://api.semanticscholar.org/graph/v1/paper/search?query={{ $json.search_query }}&limit=2&fields=title,abstract,authors,openAccessPdf,year`
- Headers: `x-api-key: [your-api-key]` (if registered)

**Code** node (extract paper details):
```javascript
const papers = $input.item.json.data || [];

return papers.map(paper => ({
  id: paper.paperId,
  title: paper.title,
  summary: paper.abstract,
  authors: paper.authors.map(a => a.name).join(', '),
  pdf_url: paper.openAccessPdf?.url || null,
  published: paper.year,
  source: 'Semantic Scholar'
}));
```

**Merge results:** Use **Merge** node to combine arXiv + Semantic Scholar results

**Why this matters:** Multiple sources increase chances of finding relevant papers, but arXiv alone is sufficient for experiment.

---

## Phase 3: Implement Checkpoint 1 - Paper Review + Interest Level Selection

### 3. Add blocking checkpoint after retrieval
Using the pattern from Step 2, but **ENHANCED** with interest level selection:

**Set** node (prepare checkpoint data):
- `checkpoint_name` = "Checkpoint 1: Review Papers & Select Interest Level"
- `papers_found` = `{{ $json.length }}`
- `papers_data` = `{{ JSON.stringify($json) }}`

**Wait** node:
- Resume: "On webhook call"
- Save webhook URL

**Create enhanced review form with interest level selection:**
```html
<h2>Checkpoint 1: Review Papers & Select Interest Level</h2>

<div id="papers"></div>

<h3>Select Your Interest Level</h3>
<p>This determines what validation items you'll complete at Checkpoint 2:</p>

<form action="[webhook-url]" method="POST">
  <fieldset>
    <legend>Interest Level:</legend>

    <label>
      <input type="radio" name="interest_level" value="monitoring" required>
      <strong>MONITORING</strong> (3 items) - Just bookmarking, no action planned
    </label><br>

    <label>
      <input type="radio" name="interest_level" value="exploring">
      <strong>EXPLORING</strong> (8 items) - Serious evaluation, building business case
    </label><br>

    <label>
      <input type="radio" name="interest_level" value="pilot_ready">
      <strong>PILOT-READY</strong> (12 items) - Ready to test, resources committed
    </label><br>

    <label>
      <input type="radio" name="interest_level" value="seeking_funding">
      <strong>SEEKING FUNDING</strong> (14 items) - Fully validated, investor-ready
    </label>
  </fieldset>

  <fieldset>
    <legend>Paper Decision:</legend>
    <label>
      <input type="radio" name="decision" value="approved" required> Approve these papers
    </label><br>
    <label>
      <input type="radio" name="decision" value="refine"> Refine search query
    </label>
  </fieldset>

  <label>
    New query (if refining): <input type="text" name="new_query">
  </label>

  <button type="submit">Submit</button>
</form>

<script>
  const papersData = [YOUR_PAPERS_JSON];
  document.getElementById('papers').innerHTML = papersData.map((p, i) =>
    `<div style="border:1px solid #ccc; padding:10px; margin:10px 0;">
      <h4>${i+1}. ${p.title}</h4>
      <p><strong>Authors:</strong> ${p.authors}</p>
      <p><strong>Summary:</strong> ${p.summary.substring(0, 200)}...</p>
      <p><strong>PDF:</strong> <a href="${p.pdf_url}" target="_blank">View PDF</a> | <strong>Source:</strong> ${p.source}</p>
    </div>`
  ).join('');
</script>
```

**After Wait node - Process user decision:**
- **Set** node: Save `interest_level` to workflow state (needed for Checkpoint 2)
- **Switch** node:
  - If `decision === "approved"`: Continue to PDF processing step
  - If `decision === "refine"`: Loop back to search with `new_query`

**Why this matters:**
- This checkpoint validates papers AND captures partner's commitment level
- Interest level determines validation requirements at Checkpoint 2
- Tests the core tiered validation UX that's central to your marketplace design

---

## Phase 4: Test End-to-End

### 4. Test the complete retrieval workflow
**Test Scenarios:**
1. **Test Query 1:** "multimodal learning vision language models"
   - Should return papers with visual content
2. **Test Query 2:** "reinforcement learning robotics"
   - Should return papers with experimental results

**For each test:**
1. Execute workflow
2. Review papers at Checkpoint 1
3. Approve or refine
4. Document: Were papers relevant? Did checkpoint work?

**Metrics to capture:**
- API response time
- Number of papers retrieved
- Relevance (subjective 1-10 rating)
- Checkpoint UX (easy to use? State preserved?)

**Why this matters:** Testing reveals issues early before building the more complex PDF analysis steps.

---

## Output Requirements

At the end of this step, create/update:

1. **n8n Workflow:** "Paper Retrieval with Checkpoint 1"
   - Saved in n8n
   - Working end-to-end

2. **File:** `your_workspace/your_workflows/research_analysis_experiment/retrieval_test_results.md`
```markdown
# Paper Retrieval Test Results

## Test 1: [Query]
- **Papers Found:** [Number]
- **Relevance Rating:** [1-10]
- **Checkpoint Behavior:** [Working? Issues?]
- **Time to Complete:** [Minutes]

## Test 2: [Query]
- **Papers Found:** [Number]
- **Relevance Rating:** [1-10]
- **Checkpoint Behavior:** [Working? Issues?]
- **Time to Complete:** [Minutes]

## Issues Encountered
- [List any problems and solutions]

## Readiness for Step 4
- [ ] Retrieval works for both test queries
- [ ] Checkpoint 1 blocks and resumes correctly
- [ ] State persists (can access papers after checkpoint)
- [ ] PDF URLs are valid

**Date Completed:** [Date]
**Time Spent:** [Hours]
```

---

## Instructions for the AI Assistant

- Start with arXiv only (simpler) before adding Semantic Scholar
- Help debug API response parsing (XML to JSON can be tricky)
- Ensure PDF URLs are captured - they're needed for Step 4
- Test checkpoint thoroughly - this pattern will be reused for Checkpoints 2 & 3
- If search returns 0 papers, help refine the query
- Encourage user to test with queries that will return papers with images/tables (important for PDF processing test)
- Document everything - these notes will help when scaling to Phase 1 MVP
